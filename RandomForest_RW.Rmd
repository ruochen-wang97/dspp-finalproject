---
title: "Modelling and Prediction"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages, echo=T, message=F, warning=F}

library(haven)
library(tidyverse)
library(lubridate)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)
library(ranger)
```

```{r split-and-preprocess-data-for-rf, echo=T, message=F, warning=F}

# read in data
claims_data <- read_csv("data/clean/merged.csv")

# make dataset
claims_data <- claims_data %>%
  select(initial_claims_2020_03_21, initial_claims_2020_03_28, initial_claims_2020_04_04, initial_claims_2020_04_11, continued_claims_2020_03_21, continued_claims_2020_03_28, continued_claims_2020_04_04, continued_claims_2020_04_11, sah_date, days_since_peak_deaths, sum_conf, sum_deaths, Incident_Rate, Mortality_Rate, region, topind_gdp, topindemp_1, topindemp_2, topindemp_3, totpop_2018, pctpop_work, pctpop_hs, gov_republican) %>%
  mutate(days_since_sah = as.Date("2020-04-11") - ymd(sah_date)) %>%
  mutate(days_since_sah = replace_na(days_since_sah, 0)) %>%
  mutate(days_since_peak = days_since_peak_deaths - 21) %>%
  mutate(gov_republican = factor(gov_republican)) %>%
  select(-sah_date)

# split data into training and testing sets
set.seed(20200504)

claims_split <- initial_split(claims_data, prop = .8)
claims_training <- training(claims_split)
claims_testing <- testing(claims_split)
# and the testing set is now under lock and key!!!

# create recipe for rf
recipe_claims <- recipe(formula = initial_claims_2020_04_11 ~.,
                        data = claims_training) %>%
  step_string2factor(region, topind_gdp, topindemp_1, topindemp_2, topindemp_3) %>%
  step_dummy(gov_republican) %>%
  prep()

# create 10-fold
claims_resamples <- vfold_cv(data = claims_training, v = 10)
```

```{r create-custom-function-for-resamples, echo=T, message=F, warning=F}

# create custom function
train_claims <- function(model, split, formula, try, tree, k) {
  
  # create analysis data from split
  claims_analysis <- analysis(split)
  
  # set model
  if(model == "rf") {
    model_claims <- rand_forest(mode = "regression",
                                mtry = try,
                                trees = tree) %>%
      set_engine("ranger",
                 importance = "impurity") %>%
      fit(formula = formula,
          data = bake(object = recipe_claims,
                      new_data = claims_analysis))
  }
  else if(model == "cart") {
    model_claims <- decision_tree(mode = "regression") %>%
      set_engine("rpart") %>%
      fit(formula = formula,
          data = bake(object = recipe_claims,
                      new_data = claims_analysis))
  }
  
  # create assessment data from split
  claims_assessment <- assessment(split)
  
  # get predictions on assessment data and colculate out-of-sample rmse for split
  rmse <- bind_cols(
    claims_assessment,
    predict(model_claims, bake(object = recipe_claims,
                               new_data = claims_assessment))) %>%
    rmse(truth = initial_claims_2020_04_11, estimate = .pred) %>%
    pull(.estimate)
  
  return(rmse)
}
```

```{r pick-model-and-train-on-training-data, echo=T, message=F, warning=F}

# calculate RMSEs for : apply custom function to resamples

claims_resamples <- claims_resamples %>%
  mutate(
    rmse_1 = map_dbl(.x = splits,
                     .f = ~train_claims(model = "rf",
                                        formula = initial_claims_2020_04_11 ~ .,
                                        split = .x,
                                        try = 5,
                                        tree = 50))
  ) %>%
  mutate(
    rmse_2 = map_dbl(.x = splits,
                     .f = ~train_claims(model = "rf",
                                        formula = initial_claims_2020_04_11 ~ .,
                                        split = .x,
                                        try = 10,
                                        tree = 100))
  ) %>%
  mutate(
    rmse_3 = map_dbl(.x = splits,
                     .f = ~train_claims(model = "rf",
                                        formula = initial_claims_2020_04_11 ~ .,
                                        split = .x,
                                        try = 20,
                                        tree = 500))
  ) %>%
  mutate(
    rmse_4 = map_dbl(.x = splits,
                     .f = ~train_claims(model = "cart",
                                        formula = initial_claims_2020_04_11 ~ .,
                                        split = .x))
  )
    
glimpse(claims_resamples)

# compare rf and cart
claims_resamples <- claims_resamples %>%
  select(-splits)

knitr::kable(claims_resamples)
knitr::kable(rmse_avg <- c(mean(claims_resamples$rmse_1),
                           mean(claims_resamples$rmse_2),
                           mean(claims_resamples$rmse_3),
                           mean(claims_resamples$rmse_4)),
             col.names = "RMSE"
)
```


```{r visualize RMSE for different resamples}

claims_resamples %>%
  pivot_longer(-id) %>%
  ggplot(aes(x = id,
             y = value,
             color = name,
             group = name)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(limits = c(0, NA)) +
  theme_minimal()

```

```{r calculating means across 10 resamples}

claims_resamples %>%
  summarize(mean(rmse_1),
            mean(rmse_2),
            mean(rmse_3),
            mean(rmse_4))
```

Estimating out of sample error rate

```{r fitting model to testing data}

# Final prediction on testing data
model_final <-
  rand_forest(mode = "regression") %>%
  set_engine("ranger",
             importance = "impurity") %>%
  fit(initial_claims_2020_04_11 ~.,
      data = claims_training)


# Adding predicted values column to testing data
claims_testing <- bind_cols(
  claims_testing,
  pred_claims_2020_04_18 = predict(model_final, claims_testing)
) 


# Error metric estimation
bind_cols(
  claims_testing,
  pred_claims_2020_04_18 = predict(model_final, claims_testing)
) %>%
  metrics(truth = initial_claims_2020_04_11, 
          estimate = .pred)
```
