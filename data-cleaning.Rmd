---
title: "Data Cleaning and Descriptive Analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Data Cleaning

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, message=F, warning=F, results='hide')
```

```{r load-packages}

library(readxl)
library(haven)
library(tidyverse)
library(tidyr)
library(ggplot2)
library(treemapify)
library(ggridges)
```

### Unemployment Claims

```{r unemp-clean, echo=T, message=F, warning=F}

claims <- read_excel("data/raw/unemployment_bystate_weekly.xls")

claims <- claims %>%
  rename(state_name = State) %>%
  rename_all(~str_to_lower(colnames(claims))) %>%
  rename_all(~str_replace_all(., "\\s+", "_")) %>%
  filter(state != "Puerto Rico" &
           state != "Virgin Islands" ) %>%
  select(state, filed_week_ended, initial_claims, continued_claims)

# change data to wide
claims <-
  pivot_wider(data = claims,
              names_from = filed_week_ended,
              values_from = c(initial_claims, continued_claims))
```

### GDP by Industry

```{r gdp-clean, echo=T, message=F, warning=F}

gdp <-
  read.csv("data/raw/gdp_bystate_byindustry_2019.csv")

gdp <- gdp %>%
  filter(str_detect(string = Description,
                    pattern = "    ")) %>% 
  filter(!str_detect(string = Description, 
                     pattern = "     ")) %>% # remove aggregate & sub-industries
  filter(GeoName != "United States") %>% # remove federal data
  filter(X2019 != "(NA)" & X2019 != "(D)") %>% # remove non-numeric values
  rename(gdp2019 = X2019, state = GeoName) # rename GDP and state variables

# change data to wide
gdp <- gdp %>% 
  pivot_wider(names_from = Description, state,
              values_from = gdp2019) %>%
  filter(!state %in% c("New England", "Mideast", "Great Lakes", "Plains", "Southeast", "Southwest", "Rocky Mountain", "Far West"))

# find top industry wrt gdp
gdp <- gdp %>%
  mutate(topind_gdp = colnames(gdp)[apply(gdp, 1, which.max)]) %>%
  select(state, topind_gdp)
```

### Per Capita Personal Income

```{r inc-clean, echo=T, message=F, warning=F}

income <- read_csv("data/raw/percapitapersonalincome_bystate_2019.csv")

income <- income %>%
  filter(as.numeric(GeoFips) >= 1000 & as.numeric(GeoFips) <= 56000) %>% # remove fed/regional data
  rename(personal_inc2019 = "2019", state = GeoName) %>%
  select(-GeoFips)
```

### Employment by Occupation

```{r occ-clean, echo=T, message=F, warning=F}

occ <- read_excel("data/raw/employment_byoccupation_bystate_may2019.xlsx")

occ <- occ %>%
  filter(o_group == "major") %>%
  select(area_title, occ_code, occ_title, jobs_1000) %>%
  mutate(jobs_1000 = as.numeric(jobs_1000)) %>%
  rename(state = area_title) %>%
  group_by(state) %>%
  mutate(rank = rank(-jobs_1000)) %>%
  filter(rank <= 3) %>%
  select(-jobs_1000)

# change data to wide and rename vars
occ <- occ %>% 
  pivot_wider(names_from = rank, state,
              values_from = occ_title) %>%
  rename(topindemp_3 = 2, topindemp_1 = 3, topindemp_2 = 4)
```

### Census Region

```{r regions-clean, echo=T, message=F, warning=F}

regions <- read_excel("data/raw/censusregion_bystate.xlsx")

regions <- regions %>%
  select(State, Region) %>%
  rename(state = State, region = Region)
```

### Merge Datasets

```{r merge, echo=T, message=F, warning=F}
clean_data <-
  left_join(claims, income, by = "state")
anti_join(clean_data, income)

clean_data <-
  left_join(clean_data, gdp, by = "state")
anti_join(clean_data, gdp)

clean_data <-
  left_join(clean_data, occ, by = "state")
anti_join(clean_data, occ)

clean_data <-
  left_join(clean_data, regions, by = "state")
anti_join(clean_data, regions)
```

```{r merge-sah-date, echo=T, message=F, warning=F}

# load & add stay at home date data
sah <- read_excel("data/raw/stayathome.xlsx")

clean_data <-
  left_join(clean_data, sah, by = "state")
anti_join(clean_data, sah)
```

```{r merge-peak-date, echo=T, message=F, warning=F}

#load & add peak death data

sah_peakdeaths <- read_excel("data/raw/sah_peakdeaths.xlsx")

clean_data <-
  left_join(clean_data, sah_peakdeaths, by = "state") %>%
  rename(massgath_res_date = mg_restr,
         noness_res_date = noness_restr)
anti_join(clean_data, sah_peakdeaths)
```

```{r merge-ed-attainment, echo=T, message=F, warning=F}

# load & add ed attainment data
edattain <- read_csv("data/raw/edattain_bystate_2018.csv")

clean_data <-
  left_join(clean_data, edattain, by = "state")
anti_join(clean_data, edattain)
```

```{r merge-working-pop, echo=T, message=F, warning=F}

# load & add working pop data
pctworkpop <- read_csv("data/raw/popest_bystate_2018.csv") %>%
  select(state, totpop_2018, totpop_work, pctpop_work)

clean_data <-
  left_join(clean_data, pctworkpop, by = "state")
anti_join(clean_data, pctworkpop)
```

```{r merge-gov-party, echo=T, message=F, warning=F}

# load & add governor party data
party <- read_excel("data/raw/party_bystate_2020.xlsx")

clean_data <-
  left_join(clean_data, party, by = "state")
anti_join(clean_data, party)
```

```{r merge-death-num-till-apr18, echo=T, message=F, warning=F}

# load packages
library(httr)
library(RCurl)

# read in JHU COVID data from Github for April 18, 2020
jhufile_1 = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/04-18-2020.csv"

mydata <- read.csv(url(jhufile_1))

jhu_data <- mydata %>%
  rename(state = "Province_State") %>%
  drop_na(FIPS) %>%
  filter(Country_Region == "US") 

jhu_data <- jhu_data[!(is.na(jhu_data$Admin2) | jhu_data$Admin2==""),] %>%
  select(state, Last_Update, Confirmed, Deaths, Recovered)

jhu_data_final <- jhu_data %>% 
  group_by(state) %>%
  summarise(sum_deaths = sum(Deaths),
            sum_conf = sum(Confirmed))

clean_data <-
  left_join(clean_data, jhu_data_final, by = "state")
anti_join(clean_data, jhu_data_final)
```

```{r merge-incidence-and-mortality-rate-apr18, echo=T, message=F, warning=F}

# read in JHU data on incident and mortality rates from Github for April 18, 2020
jhufile_2 = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/04-18-2020.csv"

rates_data <- read.csv(url(jhufile_2))

jhu_data_1 <- rates_data %>%
  filter(Country_Region == "US") %>%
  rename(state = "Province_State") %>%
  select(FIPS, state, Confirmed, Deaths, Lat, Long_, Incident_Rate, Mortality_Rate) %>%
  filter(FIPS < 60)

clean_data <-
  left_join(clean_data, jhu_data_1, by = "state")
anti_join(clean_data, jhu_data_1)
```

### Create Final Analytical Data

```{r final-merge, echo=T, message=F, warning=F}

# remove white space from variable names
names(clean_data) <- str_replace(names(clean_data), "-", "_") 
names(clean_data) <- str_replace(names(clean_data), "-", "_") 

clean_data %>% write_csv("data/clean/merged.csv")
```

## Descriptive Analysis

The line graph below shows the trend in new unemployment insurance claims filed in the top five US states with the highest COVID-19 incidence rates (New York, New Jersey, Massachusetts, Louisiana, Connecticut; in descending order). The number of claims was relatively low until early March when most states issued stay-at-home orders and gathering restrictions (verticle line depicts March 19 when California issued the first stay-at-home order in the US). Because of the subsequent layoffs and furloughs, a huge spike was seen in the filing of new unemployment claims. We believe the number of days since the issurance of stay-at-home order will be a good predictor for the filing of new unemployment claims due to their strong correlation showcased here.

```{r make-line-graph, echo=T, message=F, warning=F}

# build line graph data
line_data <- clean_data %>%
  select(state, 'initial_claims_2020_01_25':'initial_claims_2020_04_18', Incident_Rate) %>%
  mutate(rank = rank(-Incident_Rate)) %>%
  filter(rank <=5)

names(line_data) <- str_replace(names(line_data), "_", "-") 
names(line_data) <- str_replace(names(line_data), "_", "-") 
names(line_data) <- str_replace(names(line_data), "_", "-") 
names(line_data) <- str_replace(names(line_data), "_", "-") 

line_data_date <- line_data %>%
  gather(key = week_ended, value = initialclaims, 2:14) %>%
  mutate(week_ended = sub("initial-claims-", "", week_ended)) %>%
  mutate(week_ended = as.Date(week_ended))

# make line graph
state_rank <- c("New York",
                "New Jersey",
                "Massachusetts",
                "Louisiana",
                "Connecticut")
line_data_date$state <- factor(line_data_date$state, state_rank)

ggplot(data = line_data_date,
       mapping = aes(x = week_ended,
                     y = initialclaims,
                     group = state,
                     color = state)) +
  scale_x_date(date_breaks = "1 week") +
  geom_line() +
  geom_vline(xintercept = as.Date("2020-03-19"), linetype = 2) +
  scale_y_continuous(labels = c("0", "100,000", "200,000", "300,000", "400,000")) +
  theme_classic() +
  labs(title = "Number of New Unemployment Insurance Claims Filed in Top 5 States\nwith Highest COVID-19 Incidence Rate",
       caption = "Source: US Department of Labor & Johns Hopkins University",
       x = "Week Ending",
       y = "Number of Initial Claims") +
  theme(plot.margin = unit(c(.5, .5, .5, .5),"cm"),
        plot.title = element_text(size = 16, family = "Arial", face = "bold", vjust = 4),
        plot.caption = element_text(size = 7, family = "Arial", face = "italic", vjust = -4),
        axis.title.x = element_text(family = "Arial", vjust = -2),
        axis.title.y = element_text(family = "Arial", vjust = .5),
        axis.text.x = element_text(angle = 45, size = 7, family = "Arial", hjust = 1),
        axis.text.y = element_text(family = "Arial"),
        axis.ticks.x = element_blank())
```

The tree map below captures the relationship between the cumulative number of unemployment claims filed in each state and the total number of COVID-19 cases in each state as of April 18th. The area each state covers encodes the number of claims in that state, and the color value encodes the COVID-19 incidence rate. This visualization allows us to see the relationship between the geographic distribution of COVID-19 cases and the number of unemployment claims filed (e.g., hot spots like New York and New Jersey also have relatively large number of filed claims). We thus believe region and COVID-19 incident rate are also important predictors in our model.

```{r make-treemap, echo=T, message=F, warning=F}

# build treemap data
treemap_data <- clean_data %>%
  select(state, region, `initial_claims_2020_04_18`, `continued_claims_2020_04_18`, Incident_Rate, totpop_work) %>%
  mutate(`totclaims_2020_04_18` = `continued_claims_2020_04_18` + `initial_claims_2020_04_18`) %>%
  mutate(perc_totclaims = (`totclaims_2020_04_18`/totpop_work) * 100) %>%
  select(state, region, `totclaims_2020_04_18`, Incident_Rate, perc_totclaims)

# make treemap
ggplot(data = treemap_data,
       mapping = aes(area = `totclaims_2020_04_18`,
                     fill = Incident_Rate,
                     label = `state`,
                     subgroup = region)) +
  geom_treemap() +
  geom_treemap_subgroup_border(color = "white") +
  geom_treemap_text(color = "white",
                    place = "center",
                    grow = F,
                    reflow = T) +
  geom_treemap_subgroup_text(color = "#FAFAFA",
                             place = "center",
                             grow = T,
                             alpha = .5,
                             min.size = 0) +
  scale_fill_gradient(low = "#fdbb84", high = "#b30000",
                      breaks = seq(50, 1500, by = 500),
                      name = "Number of COVID Cases\nper 100,000 Residents") +
  labs(title = "Total Unemployment Insurance Claims Filed, as of April 18",
       caption = "Source: US Department of Labor & Johns Hopkins University") +
  theme(plot.margin = unit(c(.5, .5, .5, .5),"cm"),
        plot.title = element_text(size = 16, family = "Arial", face = "bold", vjust = 2),
        plot.caption = element_text(size = 7, family = "Arial", face = "italic", vjust = -2),
        legend.title = element_text(size = 9, family = "Arial", vjust = 4),
        legend.text = element_text(family = "Arial"))
```

<<<<<<< HEAD
The tree map above captures the total number of US uninsurance claims filed as of April 18th and the number of COVID-19 cases. States are grouped by region and the area each state covers is proportional to the number of claims filed. The color of each area corresponds to the number of COVID-19 cases; states with higher COVID-19 cases have darker colored areas. This visualization allows us to see regional patterns in the spread of COVID-19 as well as the number of unemployment claims filed. Most affected population have been the self-employed and gig workers, as well as workers in hospitality industry such as restaurants, who were made eligible for unemployement benefits when they experienced job losses.
=======
The scatterplot below unveils the relationship between COVID-19 incident rate and proportion of labor force filing for unemployment in each state. The dots on the scatterplot represent states, which are also colored by the party of the state governor. The graph shows a moderately positive correlation between COVID-19 incidence rate and proportion of labor force filing for unemployment - this makes sense since the spread of COVID-19 forces employers to shut down and laying off workers, leaving many unemployed. The relationship also appears to be mostly driven by states with Democrat governors, as many of them have higher incidence rates than Republican states. This relationship is informative for our model as it shows us the interaction between these three variables.

```{r make-scatter-plot, echo=T, message=F, warning=F}
>>>>>>> 40a3318e050f1504fde92b04c5adf4518e5c48b3

clean_data %>%
  mutate(perc_claim = (`continued_claims_2020_04_18`/totpop_2018) * 100) %>%
  ggplot() +
  geom_point(mapping = aes(x = perc_claim, y = Incident_Rate, 
                           color = as.character(gov_republican)),
             alpha = 0.5) + 
  scale_color_manual(name = "Party of State Governor",
                     labels = c("Democrat", "Republican"), 
                     values = c("blue", "red")) +
  labs(title = 
         paste("COVID-19 Incidence and Continued Claims by State Party"),
       caption = "Source: US Department of Labor & Johns Hopkins University",
       x = "Incidence Rate",
       y = "Percent of work force that filed claims") + 
  theme_minimal() +
  theme(panel.grid.major = element_line(linetype = "dotted", color = "gray")) +
  theme(panel.grid.minor = element_blank()) +
  theme(plot.margin = unit(c(.5, .5, .5, .5),"cm"),
        plot.title = element_text(size = 16, family = "Arial", face = "bold", vjust = 2),
        plot.caption = element_text(size = 7, family = "Arial", face = "italic", vjust = -2),
        legend.title = element_text(size = 9, family = "Arial", vjust = 4),
        legend.text = element_text(family = "Arial")) 
```
 
The ridgeplot below shows the distribution of the number of days since the peak COVID-19 deaths as of April 18, broken down by region. Although this graph only shows braod patterns, it is useful for understanding which regions will be combating COVID-19 and (possibly) see increased unemployment claims for a longer period.

<<<<<<< HEAD
The scatterplot above shows the relationship between continued unemployment claims filed and the COVID-19 incidence rate among US states. The points on the scatterplot are also colored by the party of the state governor. The graph shows a moderately positive relationship between COVID-19 incidence rates and continued claims as a percentage of the working population. This makes sense as the spread of COVID-19 has forced employers to shut down, leaving many unemployed. The relationship appears to be mostly driven by states with Democrat governors, as many of them have higher incidence rates than Republican states. This relationship is informative for our model becasue it shows that COVID-19 incidence rates are associated (to some degree) with the number of unisurance claims, which makes it a good predictor. 
=======
```{r make-ridge-plot, echo=T, message=F, warning=F}
>>>>>>> 40a3318e050f1504fde92b04c5adf4518e5c48b3

# create variable for peak since April 18th

clean_data <- clean_data %>%
  mutate(peak = days_since_peak_deaths - 14) 

# this plot shows the distribution of days since peak deaths (as of april 18th) divided by region

ggplot(data = clean_data, mapping = aes(x = peak, y = as.factor(region))) +
  geom_density_ridges(fill = "#1696d2") +
  labs(title = 
         paste("Distribution of Days Since Predicted COVID-19 \nPeak Deaths by Region"),
       caption = "Source: Institute for Health Metrics and Evaluation",
       x = "Days since peak deaths (as of April 18)",
       y = "Region") +
  theme_minimal() +
   theme(plot.margin = unit(c(.5, .5, .5, .5),"cm"),
        plot.title = element_text(size = 16, family = "Arial", face = "bold", vjust = 2),
        plot.caption = element_text(size = 7, family = "Arial", face = "italic", vjust = -2),
        legend.title = element_text(size = 9, family = "Arial", vjust = 4),
        legend.text = element_text(family = "Arial")) 
```
